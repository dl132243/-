1# linear-regession

线性回归


通过属性的线性组合进行建立预测模型，目的是找到一条直线，一个平面或者超平面使得真实值和预测值的误差最小化。


y = wT * x + error 其中误差服从独立同分布和高斯分布。 w为权重参数， 建立模型过程就是求得最佳参数使得误差最小化


求解最佳参数方法有两种： 

1. 梯度下降法 2. 最小二乘法


注意： 

1. 梯度下降法求解时：

   （1）先对特征进行归一化，提高模型的收敛速度

   （2）选取learning rate 很重要， 学习率太小时，w 收敛很慢，而 学习率太大时，下降很快但是容易造成两边跳跃，造成无法收敛。

       一般而言，学习率选取0.01，0.005等，
       

过拟合现象： 标样拟合预测很好，但是缺少泛化能力，对待测样本的预测能力很差。 处理过拟合的问题，一般使用正则化方法：

L1正则化 ： + a *|w|
L2正则化：  + a * |w|^2

L1 正则化可能会使部分权重参数w 趋近于0, 而L2 正则化 使得权重参数差别不会太大。


2. 最小二乘法求解时，需要用到极大似然对数定律。


  求解得到： w = (xT*x)^-1 * XT * y   需要注意 xT * x的逆是否存在。
  
  引入L2正则化后得到：
  
  w = (xTX + 2aI)-1 * xT *y 
  
  其中 xTx + 2aI 为正定矩阵，其存在逆矩阵。


 
